
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    tr.spaceUnder>td {
        padding-bottom: 10px;
    }
    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>EvolveGraph</title>
        <meta property="og:title" content="sceneflow" />
        <!-- <meta property="og:url" content="https://www.youtube.com/watch?v=cYHQKtBLI3Q" /> -->
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">SoNIC: Safe Social Navigation with Adaptive Conformal Inference and Constrained Reinforcement Learning </span>


    <!-- </center> -->
    
    <br>
    <br>
      <table align=center width=800px>

     <tr>
       <span style="font-size:22px"><a href="https://jyao97.github.io/">Jianpeng Yao</a></span>,&nbsp;&nbsp;
       <span style="font-size:22px">Xiaopan Zhang</span>,&nbsp;&nbsp;
       <span style="font-size:22px">Yu Xia</span>,&nbsp;&nbsp;
       <span style="font-size:22px">Zejin Wang</span>,&nbsp;&nbsp;
       <span style="font-size:22px">Amit K. Roy-Chowdhury</span>,&nbsp;&nbsp;
       <span style="font-size:22px"><a href="https://jiachenli94.github.io/">Jiachen Li*</a></span>&nbsp;&nbsp;
   </tr>


     <tr>
      <td align=center colspan="2" style="font-size:22px">
      <center>
      University of California, Riverside
      </center>
      </td>

    </table>

        <br> 
    <table align=center width=700px>
       <tr>
        <td align=center width=100px>
        <center>
        <!-- <span style="font-size:28px">NeurIPS 2020 </span> -->
        </center>
        </td>
     </tr>
    </table>
         <table align=center width=900>
          <tr>
                
                 <span style="font-size:28px">
                [Paper] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                [Video] &nbsp; &nbsp; &nbsp; &nbsp;
                [Bibtex] &nbsp; &nbsp; &nbsp; &nbsp; 

              </span>
              <br>
             <!-- <br>
              <br>
              <br> -->
              <!--
              <center><h1>Overview Video</h1></center>
              <iframe width="900" height="660" src="https://www.youtube.com/embed/XCWCHwGlBgE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
            <!-- [hosted on <a href="#">arXiv</a>]</a> -->
              </td>
        </tr>
      </table>
            <!--
            <br>
            <table align=center width=600px>
                <tr>
                    <td width=700px>
                      <center>
                          <img src = "teaser.jpg" height="180px"></img><br>
                    </center>
                    </td>
                </tr>

                <tr>
                  <td colspan="3"> <br>
                In the first image, can you predict what the human is going to do next? Depending on his intention, the person can choose to turn left to climb up stairs; he may also go straight through the hallway or turn right to fetch some items off the table. In this work, we propose a method to generate long-term stochastic predictions of future 3D human motion, while also considering the scene context.
    Given one single RGB image and 2D human pose history, our method first generates multiple possible future 2D destinations, then predicts future 3D human paths towards each destination, as shown in the middle, and finally generates 3D human pose sequences following the path, shown in the ground-truth 3D point cloud of the scene in the right. We train our model on both real-world data with noisy ground-truth and our newly-created large-scale synthetic data with diverse scenes, characters, and motions. Both quantitative comparisons and qualitative results demonstrate that our method can generate plausible scene-adaptive predictions.
                  </td>
                </tr>
            </table>


          <hr> -->
<!--           <br>
          <br> -->
<!--           <center>
            <table align=center width=700>
                <tr>
              
                  <td><video width="700px" controls> <source src="hmp.m4v" type=video/mp4><video></td>
              
              </tr>
            </table>
          </center> -->
          
          <br>

          <!-- <hr> -->
          <center><h1>Abstract</h1></center>
          <table align=center width=1000px>
              <tr>
                  <td width=1000px>
<!--                     <center>
                        <img src = "teaser.jpg" height="500px"></img><br>
                  </center> -->
                  <br>
                  <span style="font-size:20px"> Reinforcement Learning (RL) has enabled social
                    robots to generate trajectories without human-designed rules
                    or interventions, which makes it more effective than hard-
                    coded systems for generalizing to complex real-world scenarios.
                    However, social navigation is a safety-critical task that requires
                    robots to avoid collisions with pedestrians while previous RL-
                    based solutions fall short in safety performance in complex
                    environments. To enhance the safety of RL policies, to the best
                    of our knowledge, we propose the first algorithm, SoNIC, that
                    integrates adaptive conformal inference (ACI) with constrained
                    reinforcement learning (CRL) to learn safe policies for social
                    navigation. More specifically, our method augments RL observations 
                    with ACI-generated nonconformity scores and provides
                    explicit guidance for agents to leverage the uncertainty metrics
                    to avoid safety-critical areas by incorporating safety constraints
                    with spatial relaxation. Our method outperforms state-of-the-art 
                    baselines in terms of both safety and adherence to social
                    norms by a large margin and demonstrates much stronger
                    robustness to out-of-distribution scenarios.
                  </td>
              </tr>

              <tr>
                <td colspan="3"> <br>

                </td>
              </tr>
          </table>


          <hr> <br>
          <center><h1>Key Ideas and Contributions</h1></center>
          <table align=center width=600px>
              <tr>
                  <td width=700px>
                    <br>
                    <center>
                        <img src = "pipeline_sonic.png" height="300px"></img><br>
                  </center>
                  <br><br>
                  <span style="font-size:18px"> <b>Framework with ACI and CRL</b>: We develop a novel framework that integrates nonconformity scores generated by ACI with CRL, which not only enhances the observation of RL agents but also directly guides the learning process of RL agents. <br><br>
                    <b>Spatial Relaxtion</b>: We propose a technique to increase the applicability of CRL in the context of social navigation by introducing spatial relaxation. Compared to previous methods, spatial relaxation provides richer cost feedback and facilitates convergence without sacrificing safety. <br><br>
                    <b>Performance Boost</b>: Our method achieves state-of-the-art (SOTA) performance in social navigation in both safety and adherence to social norms, outperforming baselines by a large margin. Our method also shows much stronger robustness to out-of-distribution (OOD) scenarios.<br>
                  </td>
              </tr>
<!-- 
We posit that pedestrians in the scene move towards a predetermined position and interactions such as social cues happen as they go along achieving this intention without changing the predilection while still shaping their trajectories locally. 
               -->
              <tr>
                <td colspan="3"> <br>

                </td>
              </tr>
          </table>

          <table align=center width=800>
            <br>
           <center><h1>Test Results in In-distribution and OOD Settings</h1></center>
              <tr class="spaceUnder">
                <td>
                  <img style="width:1050px" src="tables.png"/>
                </td>
              
              </tr>
    
            <tr>
              <td colspan="3"> <br>
                <span style="font-size:18px"><b> Quantitative Analysis</b>: In this paper, we validated SoNIC in both in-distribution and OOD settings. The experimental results demonstrate that SoNIC achieves SOTA performance in both safety and adherence to social norms and shows strong robustness to OOD scenarios. Please refer to the paper for more details.
              </td>
            </tr>
    
            
          </table>



      <hr>
            <table align=center width=950px>
                <tr>
                    <td>
                      <left>
                <center><h1>Acknowledgements</h1></center>
                This webpage template was borrowed from some <a href="https://richzhang.github.io/colorization/">colorful folks</a>.
            </left>
        </td>
        </tr>
        </table>

        <br><br>
</body>
</html>
